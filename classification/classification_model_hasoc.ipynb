{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.0.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)  \n",
    "    torch.manual_seed(seed_value)  \n",
    "    random.seed(seed_value)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  \n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/ubuntu/gaurav/in/fire/code-mixed-enma/classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Ithu ikkayude script aanu..   Uttopiya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Varunnathu manthriyo bhadano alla rajavanu ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>à´‡à´·àµà´Ÿà´®à´¾à´£àµ. But à´šà´¿à´² à´¸à´¿à´¨à´¿à´®à´¯à´¿àµ½ over actigalle à´à´¨àµ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>enna look a rajuettaaaaa............ promisin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Offensive</td>\n",
       "      <td>à´‡à´¤àµ à´®àµ‚à´àµà´šàµà´‚ à´‰à´±à´ªàµà´ªàµ  à´à´¨àµà´¤àµ à´Šà´³ à´Ÿàµà´°àµˆàµ‡à´²àµ¼</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                                  1\n",
       "0  Not_offensive              Ithu ikkayude script aanu..   Uttopiya\n",
       "1  Not_offensive    Varunnathu manthriyo bhadano alla rajavanu ra...\n",
       "2  Not_offensive    à´‡à´·àµà´Ÿà´®à´¾à´£àµ. But à´šà´¿à´² à´¸à´¿à´¨à´¿à´®à´¯à´¿àµ½ over actigalle à´à´¨àµ...\n",
       "3  Not_offensive    enna look a rajuettaaaaa............ promisin...\n",
       "4       Offensive               à´‡à´¤àµ à´®àµ‚à´àµà´šàµà´‚ à´‰à´±à´ªàµà´ªàµ  à´à´¨àµà´¤àµ à´Šà´³ à´Ÿàµà´°àµˆàµ‡à´²àµ¼"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(path/'../hasoc_task_1/ml-Hasoc-offensive-train.csv', sep='\\t', header=None)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Offensive</td>\n",
       "      <td>à´¨à´²àµà´² à´Šà´®àµà´ªà´¿à´¯ bgm à´Ÿàµ à´Ÿàµà´Ÿàµ à´Ÿàµ à´Ÿàµà´Ÿàµ‚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Offensive</td>\n",
       "      <td>Lucifer njngal randum kayyum neeti sweekarich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Evideo oru Hollywood story varunnilleee. Oru ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>ithre ullo mattavanmarude power ğŸ¤£ğŸ¤£ğŸ¤£ dislike d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Prathi poovan kozhi teaser kandittu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                                  1\n",
       "0       Offensive                 à´¨à´²àµà´² à´Šà´®àµà´ªà´¿à´¯ bgm à´Ÿàµ à´Ÿàµà´Ÿàµ à´Ÿàµ à´Ÿàµà´Ÿàµ‚...\n",
       "1       Offensive   Lucifer njngal randum kayyum neeti sweekarich...\n",
       "2  Not_offensive    Evideo oru Hollywood story varunnilleee. Oru ...\n",
       "3  Not_offensive    ithre ullo mattavanmarude power ğŸ¤£ğŸ¤£ğŸ¤£ dislike d...\n",
       "4  Not_offensive                 Prathi poovan kozhi teaser kandittu"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv(path/'../hasoc_task_1/ml-Hasoc-offensive-dev.csv', sep='\\t', header=None)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_1</td>\n",
       "      <td>Theatoril climax maathram kaanichal mathiyallo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_2</td>\n",
       "      <td>Shah Rukh Khan inte FAN cinema de cheriya samy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_3</td>\n",
       "      <td>Heavy Stills onnum oru rekshem illa adipoli fd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_4</td>\n",
       "      <td>Eee trailer njan ethra pravishyam nokiyann eni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_5</td>\n",
       "      <td>Ikka ethu engane sathikunu enna oru mass I lov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0  ml_1  Theatoril climax maathram kaanichal mathiyallo...\n",
       "1  ml_2  Shah Rukh Khan inte FAN cinema de cheriya samy...\n",
       "2  ml_3  Heavy Stills onnum oru rekshem illa adipoli fd...\n",
       "3  ml_4  Eee trailer njan ethra pravishyam nokiyann eni...\n",
       "4  ml_5  Ikka ethu engane sathikunu enna oru mass I lov..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(path/'../hasoc_task_1/ml_mixedscript_Hascoc_offensive_test_without_label.csv', header=None)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3200, 2), (400, 2), (400, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Not_offensive ': 2633, 'Offensive': 567})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Not_offensive ': 328, 'Offensive': 72})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_train, df_valid])\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_all_caps(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = replace_all_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def handle_upper_case_first_letter(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = deal_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def lower_case_everything(t: str) -> str:\n",
    "    return t.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeMixedMalayalamTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = lang\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(str(path/\"../tokenizer/mlen_spm.model\"))\n",
    "        \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/mlen_spm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(25000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxpad',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " '.',\n",
       " ',',\n",
       " 'àµ½',\n",
       " 'â–the',\n",
       " 'àµ¼',\n",
       " 'â–',\n",
       " 'àµ»',\n",
       " 's',\n",
       " 'â–â€¢',\n",
       " 'â–of',\n",
       " 'àµ¾']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25,000 is the vocab size that we chose in sentencepiece\n",
    "mlen_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lang='mlen', tok_func=CodeMixedMalayalamTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_rules.append(lower_case_everything)\n",
    "tokenizer.pre_rules.append(handle_all_caps)\n",
    "tokenizer.pre_rules.append(handle_upper_case_first_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep'],\n",
       " [<function fastai.text.transform.fix_html>,\n",
       "  <function fastai.text.transform.replace_rep>,\n",
       "  <function fastai.text.transform.replace_wrep>,\n",
       "  <function fastai.text.transform.spec_add_spaces>,\n",
       "  <function fastai.text.transform.rm_useless_spaces>,\n",
       "  <function __main__.lower_case_everything>,\n",
       "  <function __main__.handle_all_caps>,\n",
       "  <function __main__.handle_upper_case_first_letter>],\n",
       " [<function fastai.text.transform.replace_all_caps>,\n",
       "  <function fastai.text.transform.deal_caps>])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'â–tellâ–meâ–aboutâ–tourâ–self,â–mujheâ–jaannaâ–hai'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.process_all(['Tell me about TOUR self, mujhe jaanna hai'])\n",
    "''.join(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=mlen_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>â–a â– xxrep â–12 â–. â–pro mis ing â–tra il or â–x x bo s â–à´‡à´¤àµ â–à´®àµ‚ à´àµà´š àµà´‚ â–à´‰à´±à´ªàµà´ª àµ â–à´à´¨àµà´¤ àµ â–à´Š à´³ â–à´Ÿàµà´°àµˆ àµ‡ à´² àµ¼ â–x x bo s â–i k kha â–me s s â–a anu â– xxunk â–mam ook kha â– xxunk â–d q â–x x bo s â–à´¸àµ à´°à´¾à´œ àµ‡ à´Ÿàµà´Ÿ à´¨àµ â–à´•àµ‹à´®à´¡à´¿ â–à´®à´¾à´¤àµà´°à´®à´²àµà´² â–à´¸ àµ€à´°à´¿à´¯ à´¸àµ â–à´±àµ‹ à´³ àµà´•à´³àµà´‚ â–à´µ à´´ à´™àµà´™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bo s â–1 â–divas am â–3 l â–ku du tal â–tavan e â–kan una var â–a ro kke â–und â–x x bo s â–ni na kki ni â–malayalam â–in d ru sti yil â–ki da nn â–po la kka an â–pattu menn â–tho nn unnund o â–bo sse â–enna â–chodya th inu â–oru â–a da ar â–maru padi â–pra the ek shichu â–x x bo s â–tha rik ida â–sab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>â–kanda â–malaya ly â–chu nk s â–ud enkil â– xxrep â–10 â–. â–adi â–oru â–like â–x x bo s â–adi poli â–mass â–super b â–ki du â–mammootty â–poli ch â– xxrep â–4 â– xxunk â–mass â–a ay itund â–trai ler â–pa kka â–poli â–x x bo s â–i thu â–raja yu de â–3 â–strong â–all a â–et tan de â–lu ci fer â–x x bo s â–à´šàµ‡ à´Ÿàµà´Ÿ à´¨àµà´®à´¾à´° àµ‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>â– xxrep â–6 â–. â–x x bo s â–kala kki â–i thu â–box â–of i ce â–a aghosha m â–a ayirik kum â–x x bo s â–à´à´¤àµà´° â–à´•à´£àµà´Ÿ à´¿à´Ÿàµà´Ÿàµà´‚ â–à´®à´¤à´¿ à´¯à´¾à´µ à´¾à´¤àµà´¤ â–à´’à´°àµ â–à´… â–à´Ÿà´¾ àµ¼ â–it em â–x x bo s â–b g m â–uru â–raksha â–ill â– xxrep â–4 â–a â– xxrep â–4 â–. â–su shi n â–shyam â–touch â–pole . â–x x bo s â–de c â–12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>â–x x bo s â–5 â–million â–a yo â–ne â–no kkan â–vann avar â–e thra â–paru â–n de â–x x bo s â–à´šà´¾à´¨à´² à´¿à´¨àµà´±àµ† â–à´ªàµ‡à´°àµ â–à´¶àµà´°à´¦àµà´§ à´¿à´šàµà´š à´µàµ¼ à´•àµà´•àµ â–à´²àµˆ à´•àµà´•àµ â–à´…à´Ÿà´¿ à´•àµà´•à´¾à´¨àµà´³àµà´³ â–à´¸àµà´¥à´²à´‚ . . . â–x x bo s â–enik um â–ente â–family â–k kum â–ishtappett illa . . . â–dialogue s â–onnu m â–prop er â–a ayi â–mana s ila ayi lla . . â– njan â–prakasha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–i thu â– ikkayu de â–script â–a anu . . â–utt op iya,â–x x bo s â–varunnat hu â–man th ri yo â–bha da no â–all a â–raja vanu â–raja vu,â–x x bo s â–à´‡à´·àµà´Ÿ à´®à´¾à´£àµ . â–but â–à´šà´¿à´² â–à´¸à´¿à´¨à´¿à´®à´¯à´¿àµ½ â–over â–act i gal le â–à´à´¨àµà´¨àµ â–à´¤àµ‹à´¨àµà´¨ àµà´‚ . .,â–x x bo s â–enna â–look â–a â–raj u e tt â– xxrep â–5 â–a â– xxrep â–12 â–. â–pro mis ing â–tra il or,â–x x bo s â–à´‡à´¤àµ â–à´®àµ‚ à´àµà´š àµà´‚ â–à´‰à´±à´ªàµà´ª àµ â–à´à´¨àµà´¤ àµ â–à´Š à´³ â–à´Ÿàµà´°àµˆ àµ‡ à´² àµ¼\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–à´¨à´²àµà´² â–à´Š à´®àµà´ªà´¿ à´¯ â–b g m â–à´Ÿàµ â– à´Ÿàµà´Ÿàµ â–à´Ÿàµ â– à´Ÿàµà´Ÿ àµ‚ . . .,â–x x bo s â–lu ci fer â– nj ngal â–randu m â–kay yu m â–ne eti â–swe e kar ichu . . â–marichu . . â–math am â–parayunn a â–sang i kal â–ke ri â–dis like â–adukk uva aa . . . â–oru â–my rum â–nada kkulla â– xxrep â–5 â–.,â–x x bo s â–e vid eo â–oru â–hollywood â–story â–varunn ille e e . â–oru â–d b t .,â–x x bo s â–i th re â–ull o â–mat tavan maru de â–power â– xxunk â–dis like â–dis like,â–x x bo s â–pra thi â–poo van â–ko zhi â–tea s er â–kand ittu\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–the ator il â–cli ma x â–maa th ram â–kaa ni chal â–math iya llo â–en y . . . â–any â–way s â–good â–tra il or,â–x x bo s â–shah â–rukh â–khan â–inte â–fan â–cinema â–de â–cheriya â–sam yam â– kanu nu xxunk .,â–x x bo s â–heavy â–still s â–onnu m â–oru â–re ksh em â–i lla â–adi poli â–f d f s â– lock ed,â–x x bo s â–e e e â–trai ler â– njan â–e thra â–pravishya m â–no ki ya nn â–enik ku â–ari y illa â–ni ngal um â– ing ane â–tanne yanu â–i kka â–is ttam,â–x x bo s â–i kka â–e thu â–eng ane â–sa thi ku nu â–enna â–oru â–mass â–i â–love â–you â–i kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(25000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–i thu â– ikkayu de â–script â–a anu . . â–utt op iya,â–x x bo s â–varunnat hu â–man th ri yo â–bha da no â–all a â–raja vanu â–raja vu,â–x x bo s â–à´‡à´·àµà´Ÿ à´®à´¾à´£àµ . â–but â–à´šà´¿à´² â–à´¸à´¿à´¨à´¿à´®à´¯à´¿àµ½ â–over â–act i gal le â–à´à´¨àµà´¨àµ â–à´¤àµ‹à´¨àµà´¨ àµà´‚ . .,â–x x bo s â–enna â–look â–a â–raj u e tt â– xxrep â–5 â–a â– xxrep â–12 â–. â–pro mis ing â–tra il or,â–x x bo s â–à´‡à´¤àµ â–à´®àµ‚ à´àµà´š àµà´‚ â–à´‰à´±à´ªàµà´ª àµ â–à´à´¨àµà´¤ àµ â–à´Š à´³ â–à´Ÿàµà´°àµˆ àµ‡ à´² àµ¼\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–à´¨à´²àµà´² â–à´Š à´®àµà´ªà´¿ à´¯ â–b g m â–à´Ÿàµ â– à´Ÿàµà´Ÿàµ â–à´Ÿàµ â– à´Ÿàµà´Ÿ àµ‚ . . .,â–x x bo s â–lu ci fer â– nj ngal â–randu m â–kay yu m â–ne eti â–swe e kar ichu . . â–marichu . . â–math am â–parayunn a â–sang i kal â–ke ri â–dis like â–adukk uva aa . . . â–oru â–my rum â–nada kkulla â– xxrep â–5 â–.,â–x x bo s â–e vid eo â–oru â–hollywood â–story â–varunn ille e e . â–oru â–d b t .,â–x x bo s â–i th re â–ull o â–mat tavan maru de â–power â– xxunk â–dis like â–dis like,â–x x bo s â–pra thi â–poo van â–ko zhi â–tea s er â–kand ittu\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–the ator il â–cli ma x â–maa th ram â–kaa ni chal â–math iya llo â–en y . . . â–any â–way s â–good â–tra il or,â–x x bo s â–shah â–rukh â–khan â–inte â–fan â–cinema â–de â–cheriya â–sam yam â– kanu nu xxunk .,â–x x bo s â–heavy â–still s â–onnu m â–oru â–re ksh em â–i lla â–adi poli â–f d f s â– lock ed,â–x x bo s â–e e e â–trai ler â– njan â–e thra â–pravishya m â–no ki ya nn â–enik ku â–ari y illa â–ni ngal um â– ing ane â–tanne yanu â–i kka â–is ttam,â–x x bo s â–i kka â–e thu â–eng ane â–sa thi ku nu â–enna â–oru â–mass â–i â–love â–you â–i kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(25000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=25000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('../../dataset_preparation/models/best_model', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning the prtrained LM on current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [4/5 00:09<00:02]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.475304</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.444173</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.067534</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.764607</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='11' class='' max='22', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [11/22 00:01<00:01 7.2025]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.785672</td>\n",
       "      <td>5.180454</td>\n",
       "      <td>0.227307</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fit_head', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fit_head', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.175614</td>\n",
       "      <td>4.917291</td>\n",
       "      <td>0.246577</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.909992</td>\n",
       "      <td>4.443356</td>\n",
       "      <td>0.294196</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.650443</td>\n",
       "      <td>4.187945</td>\n",
       "      <td>0.319345</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.449930</td>\n",
       "      <td>4.070615</td>\n",
       "      <td>0.330060</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.321851</td>\n",
       "      <td>4.052440</td>\n",
       "      <td>0.331548</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Evideo oru Hollywood story w ill â–negative â– â–. â–oru â–avatara â–pirann'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Evideo oru Hollywood story',n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas = TextClasDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=mlen_vocab, bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>â–x x bo s â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man ju â–war ri er â–man</td>\n",
       "      <td>Not_offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>â–x x bo s â–à´¨à´¾ à´£ à´® àµà´£àµà´Ÿàµ‹ à´Ÿà´¾ â–à´šàµ† à´±àµà´± à´•à´³àµ† â–à´‡ à´®àµà´®à´¾ à´¤à´¿à´°à´¿ â–à´Š à´³ â–à´ªà´°à´¿à´ªà´¾à´Ÿà´¿ â–à´•à´¾à´£à´¿à´•àµà´• à´¾àµ» â–à´’à´°àµ â–à´Š à´³ â–à´Ÿàµà´°àµˆ à´²àµ† àµ¼ â–à´…à´¤àµ â–à´¨à´¿ à´™àµà´™àµ¾à´•àµà´•àµ à´¤à´¨àµà´¨àµ† â–à´…à´±à´¿à´¯ à´¾à´‚ â–à´à´¨àµà´¨ à´¿à´Ÿàµà´Ÿàµà´‚ â–. â–à´ˆ â–à´ªà´Ÿ à´® àµŠà´•àµà´•àµ† â–à´‡à´±à´™àµà´™ àµà´¨àµà´¨à´¤àµ â–à´¤à´¨àµà´¨àµ† â–à´†àµ¼à´•àµà´•àµà´‚ â–à´…à´±à´¿à´¯ à´¿à´²àµà´² â–. â–à´¤àµ€ à´¯àµ‡à´±àµà´± à´±à´¿àµ½ â–à´à´¤àµà´¤à´¿à´¯ à´¾àµ½ â–à´†à´³àµà´•àµ¾ â–à´à´Ÿàµà´¤àµà´¤ à´¿à´Ÿàµà´Ÿ à´² à´•àµà´•àµà´‚ â–à´…à´¤àµ à´•à´´à´¿à´àµà´ à´¾à´£àµ â–à´† à´®à´¿à´¨ à´¤à´¾ à´¤àµà´¤à´¾ à´¨àµà´±àµ† â–à´µà´°à´µ àµ â–à´šà´°à´¿à´¤àµà´°à´‚ â–à´à´™àµà´™à´¨àµ† â–à´•à´¾à´£à´¿à´•àµà´• àµà´®àµ†à´¨àµà´¨àµ</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>â–x x bo s â–i th inum â–matra m â–nall a â–review â–ki tta a an â–en thu â–the nga yaa â–e e â–pada thi lulla the nn â–enik â–maa tra ano â–tho nn iya th . . â–aake â–rasa ma ayi tt â–tho nn iya th â–2 . . . â–3 â–scene s â–matra m . . â–oru â–50 â–percent â–dia log â–onnu m â–enik â–manassil a ayi lla</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>â–x x bo s â–i th inum â–matra m â–nall a â–review â–ki tta a an â–en thu â–the nga yaa â–e e â–pada thi lulla the nn â–enik â–maa tra ano â–tho nn iya th . . â–aake â–rasa ma ayi tt â–tho nn iya th â–2 . . . â–3 â–scene s â–matra m . . â–oru â–50 â–percent â–dia log â–onnu m â–enik â–manassil a ayi lla</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>â–x x bo s â– xxunk p rit vi â–recent â–interview â–story â–tre ad â–par j irunnu â–e th nd u â–main â–katha â–th nn ea â–app ol â–vi ch rich tha â–e ger u th nn ea â–all ea â–producer â–ennu â–enni tum â–e ntha â–e thu â–ok â–par nju â–pada the â–kollu n thu â–ennu â–e e â–ci mai l â– ulla â–age ru da â–con fi d</td>\n",
       "      <td>Not_offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas.sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: TextList\n",
       "â–x x bo s â–i thu â– ikkayu de â–script â–a anu . . â–utt op iya,â–x x bo s â–varunnat hu â–man th ri yo â–bha da no â–all a â–raja vanu â–raja vu,â–x x bo s â–à´‡à´·àµà´Ÿ à´®à´¾à´£àµ . â–but â–à´šà´¿à´² â–à´¸à´¿à´¨à´¿à´®à´¯à´¿àµ½ â–over â–act i gal le â–à´à´¨àµà´¨àµ â–à´¤àµ‹à´¨àµà´¨ àµà´‚ . .,â–x x bo s â–enna â–look â–a â–raj u e tt â– xxrep â–5 â–a â– xxrep â–12 â–. â–pro mis ing â–tra il or,â–x x bo s â–à´‡à´¤àµ â–à´®àµ‚ à´àµà´š àµà´‚ â–à´‰à´±à´ªàµà´ª àµ â–à´à´¨àµà´¤ àµ â–à´Š à´³ â–à´Ÿàµà´°àµˆ àµ‡ à´² àµ¼\n",
       "y: CategoryList\n",
       "Not_offensive ,Not_offensive ,Not_offensive ,Not_offensive ,Offensive\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: TextList\n",
       "â–x x bo s â–à´¨à´²àµà´² â–à´Š à´®àµà´ªà´¿ à´¯ â–b g m â–à´Ÿàµ â– à´Ÿàµà´Ÿàµ â–à´Ÿàµ â– à´Ÿàµà´Ÿ àµ‚ . . .,â–x x bo s â–lu ci fer â– nj ngal â–randu m â–kay yu m â–ne eti â–swe e kar ichu . . â–marichu . . â–math am â–parayunn a â–sang i kal â–ke ri â–dis like â–adukk uva aa . . . â–oru â–my rum â–nada kkulla â– xxrep â–5 â–.,â–x x bo s â–e vid eo â–oru â–hollywood â–story â–varunn ille e e . â–oru â–d b t .,â–x x bo s â–i th re â–ull o â–mat tavan maru de â–power â– xxunk â–dis like â–dis like,â–x x bo s â–pra thi â–poo van â–ko zhi â–tea s er â–kand ittu\n",
       "y: CategoryList\n",
       "Offensive,Offensive,Not_offensive ,Not_offensive ,Not_offensive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: TextList\n",
       "â–x x bo s â–the ator il â–cli ma x â–maa th ram â–kaa ni chal â–math iya llo â–en y . . . â–any â–way s â–good â–tra il or,â–x x bo s â–shah â–rukh â–khan â–inte â–fan â–cinema â–de â–cheriya â–sam yam â– kanu nu xxunk .,â–x x bo s â–heavy â–still s â–onnu m â–oru â–re ksh em â–i lla â–adi poli â–f d f s â– lock ed,â–x x bo s â–e e e â–trai ler â– njan â–e thra â–pravishya m â–no ki ya nn â–enik ku â–ari y illa â–ni ngal um â– ing ane â–tanne yanu â–i kka â–is ttam,â–x x bo s â–i kka â–e thu â–eng ane â–sa thi ku nu â–enna â–oru â–mass â–i â–love â–you â–i kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(25000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: TextList\n",
       "â–x x bo s â–i thu â– ikkayu de â–script â–a anu . . â–utt op iya,â–x x bo s â–varunnat hu â–man th ri yo â–bha da no â–all a â–raja vanu â–raja vu,â–x x bo s â–à´‡à´·àµà´Ÿ à´®à´¾à´£àµ . â–but â–à´šà´¿à´² â–à´¸à´¿à´¨à´¿à´®à´¯à´¿àµ½ â–over â–act i gal le â–à´à´¨àµà´¨àµ â–à´¤àµ‹à´¨àµà´¨ àµà´‚ . .,â–x x bo s â–enna â–look â–a â–raj u e tt â– xxrep â–5 â–a â– xxrep â–12 â–. â–pro mis ing â–tra il or,â–x x bo s â–à´‡à´¤àµ â–à´®àµ‚ à´àµà´š àµà´‚ â–à´‰à´±à´ªàµà´ª àµ â–à´à´¨àµà´¤ àµ â–à´Š à´³ â–à´Ÿàµà´°àµˆ àµ‡ à´² àµ¼\n",
       "y: CategoryList\n",
       "Not_offensive ,Not_offensive ,Not_offensive ,Not_offensive ,Offensive\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: TextList\n",
       "â–x x bo s â–à´¨à´²àµà´² â–à´Š à´®àµà´ªà´¿ à´¯ â–b g m â–à´Ÿàµ â– à´Ÿàµà´Ÿàµ â–à´Ÿàµ â– à´Ÿàµà´Ÿ àµ‚ . . .,â–x x bo s â–lu ci fer â– nj ngal â–randu m â–kay yu m â–ne eti â–swe e kar ichu . . â–marichu . . â–math am â–parayunn a â–sang i kal â–ke ri â–dis like â–adukk uva aa . . . â–oru â–my rum â–nada kkulla â– xxrep â–5 â–.,â–x x bo s â–e vid eo â–oru â–hollywood â–story â–varunn ille e e . â–oru â–d b t .,â–x x bo s â–i th re â–ull o â–mat tavan maru de â–power â– xxunk â–dis like â–dis like,â–x x bo s â–pra thi â–poo van â–ko zhi â–tea s er â–kand ittu\n",
       "y: CategoryList\n",
       "Offensive,Offensive,Not_offensive ,Not_offensive ,Not_offensive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: TextList\n",
       "â–x x bo s â–the ator il â–cli ma x â–maa th ram â–kaa ni chal â–math iya llo â–en y . . . â–any â–way s â–good â–tra il or,â–x x bo s â–shah â–rukh â–khan â–inte â–fan â–cinema â–de â–cheriya â–sam yam â– kanu nu xxunk .,â–x x bo s â–heavy â–still s â–onnu m â–oru â–re ksh em â–i lla â–adi poli â–f d f s â– lock ed,â–x x bo s â–e e e â–trai ler â– njan â–e thra â–pravishya m â–no ki ya nn â–enik ku â–ari y illa â–ni ngal um â– ing ane â–tanne yanu â–i kka â–is ttam,â–x x bo s â–i kka â–e thu â–eng ane â–sa thi ku nu â–enna â–oru â–mass â–i â–love â–you â–i kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(25000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.loss_func.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MatthewsCorreff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [mcc, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.417806</td>\n",
       "      <td>0.334152</td>\n",
       "      <td>0.429945</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('first-full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.321491</td>\n",
       "      <td>0.223157</td>\n",
       "      <td>0.687972</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.246178</td>\n",
       "      <td>0.178636</td>\n",
       "      <td>0.776569</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.213831</td>\n",
       "      <td>0.085446</td>\n",
       "      <td>0.922528</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.150778</td>\n",
       "      <td>0.047230</td>\n",
       "      <td>0.965953</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112080</td>\n",
       "      <td>0.030141</td>\n",
       "      <td>0.974499</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080028</td>\n",
       "      <td>0.028110</td>\n",
       "      <td>0.983021</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.9375.\n",
      "Better model found at epoch 1 with accuracy value: 0.9775000214576721.\n",
      "Better model found at epoch 2 with accuracy value: 0.9900000095367432.\n",
      "Better model found at epoch 3 with accuracy value: 0.9925000071525574.\n",
      "Better model found at epoch 4 with accuracy value: 0.9950000047683716.\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='final')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: TextList\n",
       "â–x x bo s â–i thu â– ikkayu de â–script â–a anu . . â–utt op iya,â–x x bo s â–varunnat hu â–man th ri yo â–bha da no â–all a â–raja vanu â–raja vu,â–x x bo s â–à´‡à´·àµà´Ÿ à´®à´¾à´£àµ . â–but â–à´šà´¿à´² â–à´¸à´¿à´¨à´¿à´®à´¯à´¿àµ½ â–over â–act i gal le â–à´à´¨àµà´¨àµ â–à´¤àµ‹à´¨àµà´¨ àµà´‚ . .,â–x x bo s â–enna â–look â–a â–raj u e tt â– xxrep â–5 â–a â– xxrep â–12 â–. â–pro mis ing â–tra il or,â–x x bo s â–à´‡à´¤àµ â–à´®àµ‚ à´àµà´š àµà´‚ â–à´‰à´±à´ªàµà´ª àµ â–à´à´¨àµà´¤ àµ â–à´Š à´³ â–à´Ÿàµà´°àµˆ àµ‡ à´² àµ¼\n",
       "y: CategoryList\n",
       "Not_offensive ,Not_offensive ,Not_offensive ,Not_offensive ,Offensive\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: TextList\n",
       "â–x x bo s â–à´¨à´²àµà´² â–à´Š à´®àµà´ªà´¿ à´¯ â–b g m â–à´Ÿàµ â– à´Ÿàµà´Ÿàµ â–à´Ÿàµ â– à´Ÿàµà´Ÿ àµ‚ . . .,â–x x bo s â–lu ci fer â– nj ngal â–randu m â–kay yu m â–ne eti â–swe e kar ichu . . â–marichu . . â–math am â–parayunn a â–sang i kal â–ke ri â–dis like â–adukk uva aa . . . â–oru â–my rum â–nada kkulla â– xxrep â–5 â–.,â–x x bo s â–e vid eo â–oru â–hollywood â–story â–varunn ille e e . â–oru â–d b t .,â–x x bo s â–i th re â–ull o â–mat tavan maru de â–power â– xxunk â–dis like â–dis like,â–x x bo s â–pra thi â–poo van â–ko zhi â–tea s er â–kand ittu\n",
       "y: CategoryList\n",
       "Offensive,Offensive,Not_offensive ,Not_offensive ,Not_offensive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: TextList\n",
       "â–x x bo s â–the ator il â–cli ma x â–maa th ram â–kaa ni chal â–math iya llo â–en y . . . â–any â–way s â–good â–tra il or,â–x x bo s â–shah â–rukh â–khan â–inte â–fan â–cinema â–de â–cheriya â–sam yam â– kanu nu xxunk .,â–x x bo s â–heavy â–still s â–onnu m â–oru â–re ksh em â–i lla â–adi poli â–f d f s â– lock ed,â–x x bo s â–e e e â–trai ler â– njan â–e thra â–pravishya m â–no ki ya nn â–enik ku â–ari y illa â–ni ngal um â– ing ane â–tanne yanu â–i kka â–is ttam,â–x x bo s â–i kka â–e thu â–eng ane â–sa thi ku nu â–enna â–oru â–mass â–i â–love â–you â–i kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(25000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3600 items)\n",
       "x: TextList\n",
       "â–x x bo s â–i thu â– ikkayu de â–script â–a anu . . â–utt op iya,â–x x bo s â–varunnat hu â–man th ri yo â–bha da no â–all a â–raja vanu â–raja vu,â–x x bo s â–à´‡à´·àµà´Ÿ à´®à´¾à´£àµ . â–but â–à´šà´¿à´² â–à´¸à´¿à´¨à´¿à´®à´¯à´¿àµ½ â–over â–act i gal le â–à´à´¨àµà´¨àµ â–à´¤àµ‹à´¨àµà´¨ àµà´‚ . .,â–x x bo s â–enna â–look â–a â–raj u e tt â– xxrep â–5 â–a â– xxrep â–12 â–. â–pro mis ing â–tra il or,â–x x bo s â–à´‡à´¤àµ â–à´®àµ‚ à´àµà´š àµà´‚ â–à´‰à´±à´ªàµà´ª àµ â–à´à´¨àµà´¤ àµ â–à´Š à´³ â–à´Ÿàµà´°àµˆ àµ‡ à´² àµ¼\n",
       "y: CategoryList\n",
       "Not_offensive ,Not_offensive ,Not_offensive ,Not_offensive ,Offensive\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (400 items)\n",
       "x: TextList\n",
       "â–x x bo s â–à´¨à´²àµà´² â–à´Š à´®àµà´ªà´¿ à´¯ â–b g m â–à´Ÿàµ â– à´Ÿàµà´Ÿàµ â–à´Ÿàµ â– à´Ÿàµà´Ÿ àµ‚ . . .,â–x x bo s â–lu ci fer â– nj ngal â–randu m â–kay yu m â–ne eti â–swe e kar ichu . . â–marichu . . â–math am â–parayunn a â–sang i kal â–ke ri â–dis like â–adukk uva aa . . . â–oru â–my rum â–nada kkulla â– xxrep â–5 â–.,â–x x bo s â–e vid eo â–oru â–hollywood â–story â–varunn ille e e . â–oru â–d b t .,â–x x bo s â–i th re â–ull o â–mat tavan maru de â–power â– xxunk â–dis like â–dis like,â–x x bo s â–pra thi â–poo van â–ko zhi â–tea s er â–kand ittu\n",
       "y: CategoryList\n",
       "Offensive,Offensive,Not_offensive ,Not_offensive ,Not_offensive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (400 items)\n",
       "x: TextList\n",
       "â–x x bo s â–the ator il â–cli ma x â–maa th ram â–kaa ni chal â–math iya llo â–en y . . . â–any â–way s â–good â–tra il or,â–x x bo s â–shah â–rukh â–khan â–inte â–fan â–cinema â–de â–cheriya â–sam yam â– kanu nu xxunk .,â–x x bo s â–heavy â–still s â–onnu m â–oru â–re ksh em â–i lla â–adi poli â–f d f s â– lock ed,â–x x bo s â–e e e â–trai ler â– njan â–e thra â–pravishya m â–no ki ya nn â–enik ku â–ari y illa â–ni ngal um â– ing ane â–tanne yanu â–i kka â–is ttam,â–x x bo s â–i kka â–e thu â–eng ane â–sa thi ku nu â–enna â–oru â–mass â–i â–love â–you â–i kka\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(25000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(25000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7fac30c1cd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(25000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(25000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>Offensive</th>\n",
       "      <th>Not_offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>à´¨à´²àµà´² à´Šà´®àµà´ªà´¿à´¯ bgm à´Ÿàµ à´Ÿàµà´Ÿàµ à´Ÿàµ à´Ÿàµà´Ÿàµ‚...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>0.999782</td>\n",
       "      <td>0.000217882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lucifer njngal randum kayyum neeti sweekarich...</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>0.982383</td>\n",
       "      <td>0.0176174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evideo oru Hollywood story varunnilleee. Oru ...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.0211621</td>\n",
       "      <td>0.978838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ithre ullo mattavanmarude power ğŸ¤£ğŸ¤£ğŸ¤£ dislike d...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.0543507</td>\n",
       "      <td>0.945649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prathi poovan kozhi teaser kandittu</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.00234966</td>\n",
       "      <td>0.99765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query    actual_label  \\\n",
       "0                 à´¨à´²àµà´² à´Šà´®àµà´ªà´¿à´¯ bgm à´Ÿàµ à´Ÿàµà´Ÿàµ à´Ÿàµ à´Ÿàµà´Ÿàµ‚...       Offensive   \n",
       "1   Lucifer njngal randum kayyum neeti sweekarich...       Offensive   \n",
       "2   Evideo oru Hollywood story varunnilleee. Oru ...  Not_offensive    \n",
       "3   ithre ullo mattavanmarude power ğŸ¤£ğŸ¤£ğŸ¤£ dislike d...  Not_offensive    \n",
       "4                Prathi poovan kozhi teaser kandittu  Not_offensive    \n",
       "\n",
       "  predicted_label   Offensive Not_offensive   \n",
       "0       Offensive    0.999782    0.000217882  \n",
       "1       Offensive    0.982383      0.0176174  \n",
       "2  Not_offensive    0.0211621       0.978838  \n",
       "3  Not_offensive    0.0543507       0.945649  \n",
       "4  Not_offensive   0.00234966        0.99765  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_valid.copy()\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'query': list(df_test[1]), 'actual_label': list(df_test[0]), 'predicted_label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train[0]))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "preds = learn.get_preds(ds_type=DatasetType.Valid, ordered=True)\n",
    "for index, row in df_result.iterrows():\n",
    "    for node in all_nodes:\n",
    "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
    "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9830208371799483"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9859154929577464"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_result['actual_label'], df_result['predicted_label'], labels=['Not_offensive ', 'Offensive'], pos_label='Offensive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>Offensive</th>\n",
       "      <th>Not_offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_1</td>\n",
       "      <td>Theatoril climax maathram kaanichal mathiyallo...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.000304782</td>\n",
       "      <td>0.999695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_2</td>\n",
       "      <td>Shah Rukh Khan inte FAN cinema de cheriya samy...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.0220021</td>\n",
       "      <td>0.977998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_3</td>\n",
       "      <td>Heavy Stills onnum oru rekshem illa adipoli fd...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.000517501</td>\n",
       "      <td>0.999483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_4</td>\n",
       "      <td>Eee trailer njan ethra pravishyam nokiyann eni...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>0.0072398</td>\n",
       "      <td>0.99276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_5</td>\n",
       "      <td>Ikka ethu engane sathikunu enna oru mass I lov...</td>\n",
       "      <td>Not_offensive</td>\n",
       "      <td>5.54634e-05</td>\n",
       "      <td>0.999945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text           label  \\\n",
       "0  ml_1  Theatoril climax maathram kaanichal mathiyallo...  Not_offensive    \n",
       "1  ml_2  Shah Rukh Khan inte FAN cinema de cheriya samy...  Not_offensive    \n",
       "2  ml_3  Heavy Stills onnum oru rekshem illa adipoli fd...  Not_offensive    \n",
       "3  ml_4  Eee trailer njan ethra pravishyam nokiyann eni...  Not_offensive    \n",
       "4  ml_5  Ikka ethu engane sathikunu enna oru mass I lov...  Not_offensive    \n",
       "\n",
       "     Offensive Not_offensive   \n",
       "0  0.000304782       0.999695  \n",
       "1    0.0220021       0.977998  \n",
       "2  0.000517501       0.999483  \n",
       "3    0.0072398        0.99276  \n",
       "4  5.54634e-05       0.999945  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(path/'../hasoc_task_1/ml_mixedscript_Hascoc_offensive_test_without_label.csv', header=None)\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'id': list(df_test[0]), 'text': list(df_test[1]), 'label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train[0]))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
    "for index, row in df_result.iterrows():\n",
    "    for node in all_nodes:\n",
    "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
    "    row['label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result['label']=='Offensive'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('test_res_2nd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category Offensive, tensor(1), tensor([4.1480e-04, 9.9959e-01]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Dislike adikunna mammunikale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
