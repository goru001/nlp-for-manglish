{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.0.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)  \n",
    "    torch.manual_seed(seed_value)  \n",
    "    random.seed(seed_value)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  \n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/ubuntu/gaurav/in/fire/code-mixed-enma-2/classification_task_2\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thaankal enthaan cheyyarullath?ğŸ˜›</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ee theetam WCC feminichigalude news aarkk vena...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fukru nem tiktok oolakale vilich charcha nadat...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aashiq abu produce cheytharunnel ee problems u...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pennungal oru team aayal ath moonjum ennu epoo...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets Labels\n",
       "0                   Thaankal enthaan cheyyarullath?ğŸ˜›    NOT\n",
       "1  Ee theetam WCC feminichigalude news aarkk vena...    OFF\n",
       "2  fukru nem tiktok oolakale vilich charcha nadat...    OFF\n",
       "3  Aashiq abu produce cheytharunnel ee problems u...    NOT\n",
       "4  Pennungal oru team aayal ath moonjum ennu epoo...    OFF"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(path/'../hasoc_task_2/Malayalam_offensive_data_Training-YT.xlsx')\n",
    "df = df[['Tweets', 'Labels']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NOT': 2047, 'OFF': 1953})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/in/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thaankal enthaan cheyyarullath?ğŸ˜›</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ee theetam WCC feminichigalude news aarkk vena...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fukru nem tiktok oolakale vilich charcha nadat...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aashiq abu produce cheytharunnel ee problems u...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pennungal oru team aayal ath moonjum ennu epoo...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets Labels\n",
       "0                   Thaankal enthaan cheyyarullath?ğŸ˜›    NOT\n",
       "1  Ee theetam WCC feminichigalude news aarkk vena...    OFF\n",
       "2  fukru nem tiktok oolakale vilich charcha nadat...    OFF\n",
       "3  Aashiq abu produce cheytharunnel ee problems u...    NOT\n",
       "4  Pennungal oru team aayal ath moonjum ennu epoo...    OFF"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff = int(0.8*len(df))\n",
    "df_train = df[:cutoff]\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>Aareyum rakshapedaan anuvathikkaruthu? But Aar...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>kammikal motham udaippanu. Mukhyante nidhiyile...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>mohan lal paadi thudagiyappol Ã‚Â janam stadium ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>Abhinayathinte kaaryam thott kalichalindalla m...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>Loka tholvi...maanam kettavane</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweets Labels\n",
       "3200  Aareyum rakshapedaan anuvathikkaruthu? But Aar...    OFF\n",
       "3201  kammikal motham udaippanu. Mukhyante nidhiyile...    OFF\n",
       "3202  mohan lal paadi thudagiyappol Ã‚Â janam stadium ...    OFF\n",
       "3203  Abhinayathinte kaaryam thott kalichalindalla m...    OFF\n",
       "3204                     Loka tholvi...maanam kettavane    OFF"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = df[cutoff:]\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NOT': 1520, 'OFF': 1679})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_train['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NOT': 527, 'OFF': 273})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_valid['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MA_YT5000</td>\n",
       "      <td>Chenkol vendath thanne aayirunnu....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA_YT5001</td>\n",
       "      <td>Sundardasinte bhakshnam vakkukal ano?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MA_YT5002</td>\n",
       "      <td>Akasha dooth oru copy adi movie anu 'Who will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MA_YT5003</td>\n",
       "      <td>Purath onnum pondade... oru pennum payyanum on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MA_YT5004</td>\n",
       "      <td>Avasanam Fahad oru Oscar medikkumbazhum lalett...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                                                  1\n",
       "0  MA_YT5000               Chenkol vendath thanne aayirunnu....\n",
       "1  MA_YT5001              Sundardasinte bhakshnam vakkukal ano?\n",
       "2  MA_YT5002  Akasha dooth oru copy adi movie anu 'Who will ...\n",
       "3  MA_YT5003  Purath onnum pondade... oru pennum payyanum on...\n",
       "4  MA_YT5004  Avasanam Fahad oru Oscar medikkumbazhum lalett..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(path/'../hasoc_task_2/malayalam_hasoc_tanglish_test_without_labels.tsv', sep='\\t', header=None)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3199, 2), (800, 2), (951, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Tweets, Labels]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['Tweets'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_train, df_valid])\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['Labels']\n",
    "text_cols = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_all_caps(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = replace_all_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def handle_upper_case_first_letter(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = deal_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def lower_case_everything(t: str) -> str:\n",
    "    return t.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeMixedMalayalamTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = lang\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(str(path/\"../tokenizer/mlen_spm.model\"))\n",
    "        \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/mlen_spm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(15000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxpad',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " '.',\n",
       " 'â–the',\n",
       " ',',\n",
       " 'àµ¼',\n",
       " 'àµ½',\n",
       " 's',\n",
       " 'àµ»',\n",
       " 'â–of',\n",
       " 'â–',\n",
       " 'àµ¾',\n",
       " 'â–in']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15,000 is the vocab size that we chose in sentencepiece\n",
    "mlen_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lang='mlen', tok_func=CodeMixedMalayalamTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_rules.append(lower_case_everything)\n",
    "tokenizer.pre_rules.append(handle_all_caps)\n",
    "tokenizer.pre_rules.append(handle_upper_case_first_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep'],\n",
       " [<function fastai.text.transform.fix_html>,\n",
       "  <function fastai.text.transform.replace_rep>,\n",
       "  <function fastai.text.transform.replace_wrep>,\n",
       "  <function fastai.text.transform.spec_add_spaces>,\n",
       "  <function fastai.text.transform.rm_useless_spaces>,\n",
       "  <function __main__.lower_case_everything>,\n",
       "  <function __main__.handle_all_caps>,\n",
       "  <function __main__.handle_upper_case_first_letter>],\n",
       " [<function fastai.text.transform.replace_all_caps>,\n",
       "  <function fastai.text.transform.deal_caps>])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'â–tellâ–meâ–aboutâ–tourâ–self,â–mujheâ–jaannaâ–hai'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.process_all(['Tell me about TOUR self, mujhe jaanna hai'])\n",
    "''.join(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=mlen_vocab, label_cols=label_cols, text_cols=text_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>kka . . be dham â–aan h â–x x bo s â–aa shi q â–abu â–produce â–che y tha runn el â–e e â–problems â– undaki lla runnu â– xxrep â–5 â–. â–x x bo s â–pe nnu ngal â–oru â–team â–a ayal â–a th â–moon ju m â–ennu â–e po o â–man si laya llo â–x x bo s â– xxunk us er â–po â–oru â–raj i tha kku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>â– xxunk us er â–give â–respect â–take â–respect â–enna lle â– xxrep â–4 â–. â–abhinaya maan â–aa swa a dhana m â– xxrep â–4 â–. â–kala ye â–maa th ram â–sneh i kku â– xxrep â–5 â–. â–ka zhi vu lla var â–math re â–val ar nnu â–vann ittull u . . . val ar thi y ittull u â– xxrep â–4 â–. â–a thu â–marakka and irik aa .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>s â–mi tta yi â–vangi y ku nath â–pole a â–ala â– nj n â–film â–select â–cheyu nath . . â–tha â–i th . . â–i th xxunk . . â–bhasi st â– xxrep â–4 â– xxunk â–x x bo s â–a the â–ko o de â–ni kkum â–val lo â–nte â–karya thi l â–e da pe dan â–oru y ran um â–ava ka sha mill a â–x x bo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>â–pra an tha lla â–suhrut he â–. . ma tte the lu m â–religion â–in gan e â–point â–finger â–cheyy u van â–a ar enkil um â–samm adi ku mo . . pin ne â–ella â–math ath eyu m â–swe e gar ikunn a â–or e â–oru â–sam s kara m â–san a than dar ma m â–aan u â–x x bo s â–valare â–she riya nu â– xxrep â–4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>â–a thi lla tha vare â–ari y ichu â–nama le â–mand anmaru kku ba no â–und he shich e â–x x bo s â–iva le â–kettu na van â–end ha yal um â–oru â–ko zhi â–a ayirik kum â–x x bo s â–e th â–ge thi â–ke tta â–cinema kkarana vo , â–iva le yo ke , â–vilich e kka ne , â–malaya la â–cinema yil â–it hra â–kshama mano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (3999 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–tha an kal â–en tha an â–cheyy arullat h ? xxunk,â–x x bo s â–e e â–the e tam â–w cc â–fe mini chi ga lu de â–news â–a ar kk â–ven am . . . kondu po de . . .,â–x x bo s â–fu k ru â–ne m â–tik to k â–o ola kale â–vilich â–char cha â–na da thi ye ne kka . . be dham â–aan h,â–x x bo s â–aa shi q â–abu â–produce â–che y tha runn el â–e e â–problems â– undaki lla runnu â– xxrep â–5 â–.,â–x x bo s â–pe nnu ngal â–oru â–team â–a ayal â–a th â–moon ju m â–ennu â–e po o â–man si laya llo\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–aa reyu m â–raksha pe da an â–anu va thi kkaru thu ? â–but â–aaru m â–mind i yi lla â–ennu â–parayunnu â–than kal . â–i thu â–bjp â–ya anu â–cha i tha th enkil â–than kal â–mind ill a â–ennu â–ella avar kum â–a riya am .,â–x x bo s â–ka mmika l â–mo tham â–uda i ppan u . â–mukhya nte â–ni dhi y ile kku â–swa n tham â–sthalam â–dhanam â–che y tha â–randu â–kuttikal e â–or ma varunnu . â–na a le â–aa â–sthalat hu â–valla â–party â–of fi s um â–vara n â–chan ce â–und u .,â–x x bo s â–mohan â–lal â–pa adi â–th uda gi ya ppo l â– xxunk â–jana m â–stadium â–vittu â– xxrep â–9 â–.,â–x x bo s â–abhinaya th inte â–kaa r yam â–tho tt â–kali chal i nda lla â–mon e â–nir thi â–po da,â–x x bo s â–loka â–tho l vi . . . maan am â–ke ttava ne\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (951 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–ma xxunk y t 5 000,â–x x bo s â–ma xxunk y t 500 1,â–x x bo s â–ma xxunk y t 500 2,â–x x bo s â–ma xxunk y t 500 3,â–x x bo s â–ma xxunk y t 50 04\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(15000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(15000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=15000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f1e19fa6d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (3999 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–tha an kal â–en tha an â–cheyy arullat h ? xxunk,â–x x bo s â–e e â–the e tam â–w cc â–fe mini chi ga lu de â–news â–a ar kk â–ven am . . . kondu po de . . .,â–x x bo s â–fu k ru â–ne m â–tik to k â–o ola kale â–vilich â–char cha â–na da thi ye ne kka . . be dham â–aan h,â–x x bo s â–aa shi q â–abu â–produce â–che y tha runn el â–e e â–problems â– undaki lla runnu â– xxrep â–5 â–.,â–x x bo s â–pe nnu ngal â–oru â–team â–a ayal â–a th â–moon ju m â–ennu â–e po o â–man si laya llo\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–aa reyu m â–raksha pe da an â–anu va thi kkaru thu ? â–but â–aaru m â–mind i yi lla â–ennu â–parayunnu â–than kal . â–i thu â–bjp â–ya anu â–cha i tha th enkil â–than kal â–mind ill a â–ennu â–ella avar kum â–a riya am .,â–x x bo s â–ka mmika l â–mo tham â–uda i ppan u . â–mukhya nte â–ni dhi y ile kku â–swa n tham â–sthalam â–dhanam â–che y tha â–randu â–kuttikal e â–or ma varunnu . â–na a le â–aa â–sthalat hu â–valla â–party â–of fi s um â–vara n â–chan ce â–und u .,â–x x bo s â–mohan â–lal â–pa adi â–th uda gi ya ppo l â– xxunk â–jana m â–stadium â–vittu â– xxrep â–9 â–.,â–x x bo s â–abhinaya th inte â–kaa r yam â–tho tt â–kali chal i nda lla â–mon e â–nir thi â–po da,â–x x bo s â–loka â–tho l vi . . . maan am â–ke ttava ne\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (951 items)\n",
       "x: LMTextList\n",
       "â–x x bo s â–ma xxunk y t 5 000,â–x x bo s â–ma xxunk y t 500 1,â–x x bo s â–ma xxunk y t 500 2,â–x x bo s â–ma xxunk y t 500 3,â–x x bo s â–ma xxunk y t 50 04\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(15000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(15000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=15000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f1e19fa6d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(15000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(15000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=15000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(15000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(15000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=15000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('../../dataset_preparation/models/best_model', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.844162</td>\n",
       "      <td>5.354818</td>\n",
       "      <td>0.195714</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fit_head', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fit_head', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.335639</td>\n",
       "      <td>5.132363</td>\n",
       "      <td>0.213750</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.128068</td>\n",
       "      <td>4.781209</td>\n",
       "      <td>0.248750</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.928650</td>\n",
       "      <td>4.587447</td>\n",
       "      <td>0.267009</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.783125</td>\n",
       "      <td>4.508292</td>\n",
       "      <td>0.274554</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.689357</td>\n",
       "      <td>4.495005</td>\n",
       "      <td>0.274955</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Evideo oru Hollywood story ino lo re m . â–leonardo â–eli n anu â–a'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Evideo oru Hollywood story',n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas = TextClasDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=mlen_vocab, bs=16, label_cols=label_cols, text_cols=text_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>â–x x bo s â– xxunk us er â–ne e â–ent je lu m â–para y â–my re . . . nin de â–than ta â–annu â–close t â–vana m â–vit irunnenkil â–ne e â–i po o â–avi di run â–che la che ne â– xxrep â–4 â–. â–ni nd e â–tha lla yu m â–vedi â–n no ke â–parayunn â–a â–pe nnu ngal â–a var â–cho o shan am</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>â–x x bo s â–i ' m â–christian . . . nj ng l de â–c l g l â–e e â–jesus â–youth inte â–pa rupa di â–varu m . . . nj ng l de â–c l g il â–ella â–math avu m â–on d . . . â–i th inte â–al kar â–vann it â–o tta â–math am e â–o llu â–jesus â–is â–the â–only â–god . .</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>â–x x bo s â–ni nte â–ve e til â–ninnu â–lo an â–e du thi ttu â–all a â–my re â– nja ngal â–jeev i kunnat hu . . â– nja ngal â–ni ng alu de â–liber ty e â–hu r t â–cheyu ni lla . â– nja ngal â–end o gam y â–follow â–cheyu nnu . . â–a thu â–ver e â–aaru m â–affect â–cheyu ni lla . â–e</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>â–x x bo s â–amm u â–che chi , â–ni ngal â–lad ies â–ellavaru m â–or e â–swabhava m â–ava nam â–ennu â–vasi â– url â–patti lla llo . â– nja ngal â–aan u ngal um â–ellavaru m â–oru pole â–ull avar â–all a . â–ellavaru de yu m â–ull il â–god â– um â–de mon â– um â–und . â–aa â–s th re eyu de â–mana s ika â–nila</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>â–x x bo s â–maa ma â–madhyama ngal â–va ar tha kal â–pala thu m â–mu kku kaya nu . â–sa jan e â–po leyulla â–chil a â–nall a â–maa dhya ma â–prav ar tha kar â–mu kki ya â–va ar tha kal â–po kki â–e du thu â–janang a le â–ari yi ckunnu â–enna thu â–aa swa sam â–tha runn a â–karyam anennu â–para ya the â–vayy a .</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas.sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3999 items)\n",
       "x: TextList\n",
       "â–x x bo s â–tha an kal â–en tha an â–cheyy arullat h ? xxunk,â–x x bo s â–e e â–the e tam â–w cc â–fe mini chi ga lu de â–news â–a ar kk â–ven am . . . kondu po de . . .,â–x x bo s â–fu k ru â–ne m â–tik to k â–o ola kale â–vilich â–char cha â–na da thi ye ne kka . . be dham â–aan h,â–x x bo s â–aa shi q â–abu â–produce â–che y tha runn el â–e e â–problems â– undaki lla runnu â– xxrep â–5 â–.,â–x x bo s â–pe nnu ngal â–oru â–team â–a ayal â–a th â–moon ju m â–ennu â–e po o â–man si laya llo\n",
       "y: CategoryList\n",
       "NOT,OFF,OFF,NOT,OFF\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: TextList\n",
       "â–x x bo s â–aa reyu m â–raksha pe da an â–anu va thi kkaru thu ? â–but â–aaru m â–mind i yi lla â–ennu â–parayunnu â–than kal . â–i thu â–bjp â–ya anu â–cha i tha th enkil â–than kal â–mind ill a â–ennu â–ella avar kum â–a riya am .,â–x x bo s â–ka mmika l â–mo tham â–uda i ppan u . â–mukhya nte â–ni dhi y ile kku â–swa n tham â–sthalam â–dhanam â–che y tha â–randu â–kuttikal e â–or ma varunnu . â–na a le â–aa â–sthalat hu â–valla â–party â–of fi s um â–vara n â–chan ce â–und u .,â–x x bo s â–mohan â–lal â–pa adi â–th uda gi ya ppo l â– xxunk â–jana m â–stadium â–vittu â– xxrep â–9 â–.,â–x x bo s â–abhinaya th inte â–kaa r yam â–tho tt â–kali chal i nda lla â–mon e â–nir thi â–po da,â–x x bo s â–loka â–tho l vi . . . maan am â–ke ttava ne\n",
       "y: CategoryList\n",
       "OFF,OFF,OFF,OFF,OFF\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (951 items)\n",
       "x: TextList\n",
       "â–x x bo s â–ma xxunk y t 5 000,â–x x bo s â–ma xxunk y t 500 1,â–x x bo s â–ma xxunk y t 500 2,â–x x bo s â–ma xxunk y t 500 3,â–x x bo s â–ma xxunk y t 50 04\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(15000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(15000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f1e19fa6d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3999 items)\n",
       "x: TextList\n",
       "â–x x bo s â–tha an kal â–en tha an â–cheyy arullat h ? xxunk,â–x x bo s â–e e â–the e tam â–w cc â–fe mini chi ga lu de â–news â–a ar kk â–ven am . . . kondu po de . . .,â–x x bo s â–fu k ru â–ne m â–tik to k â–o ola kale â–vilich â–char cha â–na da thi ye ne kka . . be dham â–aan h,â–x x bo s â–aa shi q â–abu â–produce â–che y tha runn el â–e e â–problems â– undaki lla runnu â– xxrep â–5 â–.,â–x x bo s â–pe nnu ngal â–oru â–team â–a ayal â–a th â–moon ju m â–ennu â–e po o â–man si laya llo\n",
       "y: CategoryList\n",
       "NOT,OFF,OFF,NOT,OFF\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: TextList\n",
       "â–x x bo s â–aa reyu m â–raksha pe da an â–anu va thi kkaru thu ? â–but â–aaru m â–mind i yi lla â–ennu â–parayunnu â–than kal . â–i thu â–bjp â–ya anu â–cha i tha th enkil â–than kal â–mind ill a â–ennu â–ella avar kum â–a riya am .,â–x x bo s â–ka mmika l â–mo tham â–uda i ppan u . â–mukhya nte â–ni dhi y ile kku â–swa n tham â–sthalam â–dhanam â–che y tha â–randu â–kuttikal e â–or ma varunnu . â–na a le â–aa â–sthalat hu â–valla â–party â–of fi s um â–vara n â–chan ce â–und u .,â–x x bo s â–mohan â–lal â–pa adi â–th uda gi ya ppo l â– xxunk â–jana m â–stadium â–vittu â– xxrep â–9 â–.,â–x x bo s â–abhinaya th inte â–kaa r yam â–tho tt â–kali chal i nda lla â–mon e â–nir thi â–po da,â–x x bo s â–loka â–tho l vi . . . maan am â–ke ttava ne\n",
       "y: CategoryList\n",
       "OFF,OFF,OFF,OFF,OFF\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (951 items)\n",
       "x: TextList\n",
       "â–x x bo s â–ma xxunk y t 5 000,â–x x bo s â–ma xxunk y t 500 1,â–x x bo s â–ma xxunk y t 500 2,â–x x bo s â–ma xxunk y t 500 3,â–x x bo s â–ma xxunk y t 50 04\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(15000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(15000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f1e19fa6d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(15000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(15000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(15000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(15000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.loss_func.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MatthewsCorreff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [mcc, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.666853</td>\n",
       "      <td>0.632036</td>\n",
       "      <td>0.286977</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('first-full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.650479</td>\n",
       "      <td>0.560200</td>\n",
       "      <td>0.400943</td>\n",
       "      <td>0.723750</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.578573</td>\n",
       "      <td>0.466235</td>\n",
       "      <td>0.619371</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.516534</td>\n",
       "      <td>0.363603</td>\n",
       "      <td>0.709423</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(3, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.454529</td>\n",
       "      <td>0.354819</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.468962</td>\n",
       "      <td>0.285419</td>\n",
       "      <td>0.802657</td>\n",
       "      <td>0.908750</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.403044</td>\n",
       "      <td>0.236197</td>\n",
       "      <td>0.828540</td>\n",
       "      <td>0.916250</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.355547</td>\n",
       "      <td>0.190148</td>\n",
       "      <td>0.865033</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.342986</td>\n",
       "      <td>0.172694</td>\n",
       "      <td>0.888658</td>\n",
       "      <td>0.948750</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.8700000047683716.\n",
      "Better model found at epoch 1 with accuracy value: 0.9087499976158142.\n",
      "Better model found at epoch 2 with accuracy value: 0.9162499904632568.\n",
      "Better model found at epoch 3 with accuracy value: 0.9362499713897705.\n",
      "Better model found at epoch 4 with accuracy value: 0.9487500190734863.\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='final')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3999 items)\n",
       "x: TextList\n",
       "â–x x bo s â–tha an kal â–en tha an â–cheyy arullat h ? xxunk,â–x x bo s â–e e â–the e tam â–w cc â–fe mini chi ga lu de â–news â–a ar kk â–ven am . . . kondu po de . . .,â–x x bo s â–fu k ru â–ne m â–tik to k â–o ola kale â–vilich â–char cha â–na da thi ye ne kka . . be dham â–aan h,â–x x bo s â–aa shi q â–abu â–produce â–che y tha runn el â–e e â–problems â– undaki lla runnu â– xxrep â–5 â–.,â–x x bo s â–pe nnu ngal â–oru â–team â–a ayal â–a th â–moon ju m â–ennu â–e po o â–man si laya llo\n",
       "y: CategoryList\n",
       "NOT,OFF,OFF,NOT,OFF\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: TextList\n",
       "â–x x bo s â–aa reyu m â–raksha pe da an â–anu va thi kkaru thu ? â–but â–aaru m â–mind i yi lla â–ennu â–parayunnu â–than kal . â–i thu â–bjp â–ya anu â–cha i tha th enkil â–than kal â–mind ill a â–ennu â–ella avar kum â–a riya am .,â–x x bo s â–ka mmika l â–mo tham â–uda i ppan u . â–mukhya nte â–ni dhi y ile kku â–swa n tham â–sthalam â–dhanam â–che y tha â–randu â–kuttikal e â–or ma varunnu . â–na a le â–aa â–sthalat hu â–valla â–party â–of fi s um â–vara n â–chan ce â–und u .,â–x x bo s â–mohan â–lal â–pa adi â–th uda gi ya ppo l â– xxunk â–jana m â–stadium â–vittu â– xxrep â–9 â–.,â–x x bo s â–abhinaya th inte â–kaa r yam â–tho tt â–kali chal i nda lla â–mon e â–nir thi â–po da,â–x x bo s â–loka â–tho l vi . . . maan am â–ke ttava ne\n",
       "y: CategoryList\n",
       "OFF,OFF,OFF,OFF,OFF\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (951 items)\n",
       "x: TextList\n",
       "â–x x bo s â–ma xxunk y t 5 000,â–x x bo s â–ma xxunk y t 500 1,â–x x bo s â–ma xxunk y t 500 2,â–x x bo s â–ma xxunk y t 500 3,â–x x bo s â–ma xxunk y t 50 04\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(15000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(15000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f1e19fa6d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3999 items)\n",
       "x: TextList\n",
       "â–x x bo s â–tha an kal â–en tha an â–cheyy arullat h ? xxunk,â–x x bo s â–e e â–the e tam â–w cc â–fe mini chi ga lu de â–news â–a ar kk â–ven am . . . kondu po de . . .,â–x x bo s â–fu k ru â–ne m â–tik to k â–o ola kale â–vilich â–char cha â–na da thi ye ne kka . . be dham â–aan h,â–x x bo s â–aa shi q â–abu â–produce â–che y tha runn el â–e e â–problems â– undaki lla runnu â– xxrep â–5 â–.,â–x x bo s â–pe nnu ngal â–oru â–team â–a ayal â–a th â–moon ju m â–ennu â–e po o â–man si laya llo\n",
       "y: CategoryList\n",
       "NOT,OFF,OFF,NOT,OFF\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: TextList\n",
       "â–x x bo s â–aa reyu m â–raksha pe da an â–anu va thi kkaru thu ? â–but â–aaru m â–mind i yi lla â–ennu â–parayunnu â–than kal . â–i thu â–bjp â–ya anu â–cha i tha th enkil â–than kal â–mind ill a â–ennu â–ella avar kum â–a riya am .,â–x x bo s â–ka mmika l â–mo tham â–uda i ppan u . â–mukhya nte â–ni dhi y ile kku â–swa n tham â–sthalam â–dhanam â–che y tha â–randu â–kuttikal e â–or ma varunnu . â–na a le â–aa â–sthalat hu â–valla â–party â–of fi s um â–vara n â–chan ce â–und u .,â–x x bo s â–mohan â–lal â–pa adi â–th uda gi ya ppo l â– xxunk â–jana m â–stadium â–vittu â– xxrep â–9 â–.,â–x x bo s â–abhinaya th inte â–kaa r yam â–tho tt â–kali chal i nda lla â–mon e â–nir thi â–po da,â–x x bo s â–loka â–tho l vi . . . maan am â–ke ttava ne\n",
       "y: CategoryList\n",
       "OFF,OFF,OFF,OFF,OFF\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (951 items)\n",
       "x: TextList\n",
       "â–x x bo s â–ma xxunk y t 5 000,â–x x bo s â–ma xxunk y t 500 1,â–x x bo s â–ma xxunk y t 500 2,â–x x bo s â–ma xxunk y t 500 3,â–x x bo s â–ma xxunk y t 50 04\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(15000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(15000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f1e19fa6d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(15000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(15000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(15000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(15000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>NOT</th>\n",
       "      <th>OFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aareyum rakshapedaan anuvathikkaruthu? But Aar...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.340666</td>\n",
       "      <td>0.659334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kammikal motham udaippanu. Mukhyante nidhiyile...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0832142</td>\n",
       "      <td>0.916786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mohan lal paadi thudagiyappol Ã‚Â janam stadium ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.199501</td>\n",
       "      <td>0.800499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abhinayathinte kaaryam thott kalichalindalla m...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.620587</td>\n",
       "      <td>0.379413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Loka tholvi...maanam kettavane</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.146504</td>\n",
       "      <td>0.853496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query actual_label  \\\n",
       "0  Aareyum rakshapedaan anuvathikkaruthu? But Aar...          OFF   \n",
       "1  kammikal motham udaippanu. Mukhyante nidhiyile...          OFF   \n",
       "2  mohan lal paadi thudagiyappol Ã‚Â janam stadium ...          OFF   \n",
       "3  Abhinayathinte kaaryam thott kalichalindalla m...          OFF   \n",
       "4                     Loka tholvi...maanam kettavane          OFF   \n",
       "\n",
       "  predicted_label        NOT       OFF  \n",
       "0             OFF   0.340666  0.659334  \n",
       "1             OFF  0.0832142  0.916786  \n",
       "2             OFF   0.199501  0.800499  \n",
       "3             NOT   0.620587  0.379413  \n",
       "4             OFF   0.146504  0.853496  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_valid.copy()\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'query': list(df_test['Tweets']), 'actual_label': list(df_test['Labels']), 'predicted_label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train['Labels']))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "# preds = learn.get_preds(ds_type=DatasetType.Valid, ordered=True)\n",
    "for index, row in df_result.iterrows():\n",
    "    pred = learn.predict(row['query'])\n",
    "    for node in all_nodes:\n",
    "        row[node] = pred[2][learn.data.c2i[node]].item()\n",
    "    row['predicted_label'] = i2c[pred[1].data.item()]\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8861309760207781"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9255319148936171"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_result['actual_label'], df_result['predicted_label'], labels=['OFF ', 'NOT'], pos_label='OFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>NOT</th>\n",
       "      <th>OFF</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abhinayathinte kaaryam thott kalichalindalla m...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.620587</td>\n",
       "      <td>0.379413</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LALAPPAN.... iyalk ithinte valla karyavumundo</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.793384</td>\n",
       "      <td>0.206616</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>namuk enthina ingane nariya oru kodathy</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.554235</td>\n",
       "      <td>0.445765</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>amma mole interview cheythu athre ollu..a nere...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.621288</td>\n",
       "      <td>0.378712</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>veena arya enth cheythalum kozaURL</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.332914</td>\n",
       "      <td>0.667086</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>iyalk kurach cynide koduthoode</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.626035</td>\n",
       "      <td>0.373965</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>ivan evde paripadi avathariURL ithanavastha</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.436869</td>\n",
       "      <td>0.563131</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>eppoyum shakeelayude vicharame ollu kochu kallan</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.362424</td>\n",
       "      <td>0.637576</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>nadiye evdnu irakki aval ethanu</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.190991</td>\n",
       "      <td>0.809009</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>santhosh pandit nu bhudhi alpam kurava ath mat...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.534747</td>\n",
       "      <td>0.465253</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>URL cynide bomb anu</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.809044</td>\n",
       "      <td>0.190956</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>ivale angu thooki konnude veruthey manushyane ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0262124</td>\n",
       "      <td>0.973788</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ival chumma sadaranakarude nikuthy panam thinn...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.275575</td>\n",
       "      <td>0.724425</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>kurach divasamayi ivalude vivarom onnum illayi...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.265187</td>\n",
       "      <td>0.734813</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>ivale pourathan radd cheyth pakistanilek ayakanam</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.288692</td>\n",
       "      <td>0.711308</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>eni jolyum chamiyum koode kalyanam kayikum</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.700627</td>\n",
       "      <td>0.299373</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>kurach ulup koode venam kettoda koppe</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.282211</td>\n",
       "      <td>0.717789</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>joliyude adivasthrathine alav vare undallo iva...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.386068</td>\n",
       "      <td>0.613932</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>ivarude kanikal kanda thonnum e veetila gandhi...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.440264</td>\n",
       "      <td>0.559736</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>10 thalayanu ivan thani ravanan sunny kutta</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.454729</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>amma enna sangadanayod poda pulle ennu paranja...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.340738</td>\n",
       "      <td>0.659262</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>da kalla dileepe ni vanna vazhi maranalloda</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.358545</td>\n",
       "      <td>0.641455</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>ni adyam poyi thala cheevi pen kalanju vadi en...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.275961</td>\n",
       "      <td>0.724039</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>ivalk ithu pora avalude konjal angot poyi kitty</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.311947</td>\n",
       "      <td>0.688053</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>veenayeyum aryayeyum pur athakenda smayam adik...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.250766</td>\n",
       "      <td>0.749234</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>aryude achan anu big boss ennu thonunnu</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.568671</td>\n",
       "      <td>0.431329</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>aryak nannayi abinayikan ariyam..karyam kanan ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.787705</td>\n",
       "      <td>0.212295</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Njangalk ninne venda ni njangale edukanda  mone</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.375419</td>\n",
       "      <td>0.624581</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>kolayali kuttam samadichal ivan URL avde entha...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.458721</td>\n",
       "      <td>0.541279</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Ivanokke pakka rashtreeya kaaluvaari aanu...Ã°Å¸...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.514512</td>\n",
       "      <td>0.485488</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Adutha election munnil kande.oru maple kakkanu...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.494072</td>\n",
       "      <td>0.505928</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>P sasi pk sasi goURL ivare ariyamo molkku</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.481966</td>\n",
       "      <td>0.518034</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>Evale kaalum paavapettavar nthoram peeru und U...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.325437</td>\n",
       "      <td>0.674563</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>ithu congresskareyum kaliyakumbo parayanam....kto</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.493561</td>\n",
       "      <td>0.506439</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Aarayalum ninte uppa aakathirinnal matahi.kash...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.472334</td>\n",
       "      <td>0.527666</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Enna URL Njan nale neram veluthitt varam, ille...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.16658</td>\n",
       "      <td>0.83342</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>@USER Abisher da potta lolanea kanikkunnudallo...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.276147</td>\n",
       "      <td>0.723853</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>Njan oru muslim aan,full support chechee,enik ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.498726</td>\n",
       "      <td>0.501274</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>Mole achanteyum ammayudem vila ariyathondaaaa</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.228978</td>\n",
       "      <td>0.771022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Ninaku.pattumengil.sthree.kalku.upakaramulla.k...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.278984</td>\n",
       "      <td>0.721016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Ahana chachiii nalla video aaaa egane parayunn...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.462916</td>\n",
       "      <td>0.537084</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>first night video ittamathiyayirunnu veetukark...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.691978</td>\n",
       "      <td>0.308022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 query actual_label  \\\n",
       "3    Abhinayathinte kaaryam thott kalichalindalla m...          OFF   \n",
       "11       LALAPPAN.... iyalk ithinte valla karyavumundo          OFF   \n",
       "19             namuk enthina ingane nariya oru kodathy          OFF   \n",
       "49   amma mole interview cheythu athre ollu..a nere...          OFF   \n",
       "67                  veena arya enth cheythalum kozaURL          NOT   \n",
       "74                      iyalk kurach cynide koduthoode          OFF   \n",
       "78         ivan evde paripadi avathariURL ithanavastha          NOT   \n",
       "99    eppoyum shakeelayude vicharame ollu kochu kallan          NOT   \n",
       "112                    nadiye evdnu irakki aval ethanu          NOT   \n",
       "128  santhosh pandit nu bhudhi alpam kurava ath mat...          OFF   \n",
       "161                                URL cynide bomb anu          OFF   \n",
       "167  ivale angu thooki konnude veruthey manushyane ...          NOT   \n",
       "176  ival chumma sadaranakarude nikuthy panam thinn...          NOT   \n",
       "182  kurach divasamayi ivalude vivarom onnum illayi...          NOT   \n",
       "211  ivale pourathan radd cheyth pakistanilek ayakanam          NOT   \n",
       "229         eni jolyum chamiyum koode kalyanam kayikum          OFF   \n",
       "254              kurach ulup koode venam kettoda koppe          NOT   \n",
       "256  joliyude adivasthrathine alav vare undallo iva...          NOT   \n",
       "261  ivarude kanikal kanda thonnum e veetila gandhi...          NOT   \n",
       "262        10 thalayanu ivan thani ravanan sunny kutta          NOT   \n",
       "281  amma enna sangadanayod poda pulle ennu paranja...          NOT   \n",
       "295        da kalla dileepe ni vanna vazhi maranalloda          NOT   \n",
       "301  ni adyam poyi thala cheevi pen kalanju vadi en...          NOT   \n",
       "334    ivalk ithu pora avalude konjal angot poyi kitty          NOT   \n",
       "345  veenayeyum aryayeyum pur athakenda smayam adik...          NOT   \n",
       "348            aryude achan anu big boss ennu thonunnu          OFF   \n",
       "350  aryak nannayi abinayikan ariyam..karyam kanan ...          OFF   \n",
       "373    Njangalk ninne venda ni njangale edukanda  mone          NOT   \n",
       "407  kolayali kuttam samadichal ivan URL avde entha...          NOT   \n",
       "473  Ivanokke pakka rashtreeya kaaluvaari aanu...Ã°Å¸...          OFF   \n",
       "490  Adutha election munnil kande.oru maple kakkanu...          NOT   \n",
       "531          P sasi pk sasi goURL ivare ariyamo molkku          NOT   \n",
       "544  Evale kaalum paavapettavar nthoram peeru und U...          NOT   \n",
       "579  ithu congresskareyum kaliyakumbo parayanam....kto          NOT   \n",
       "585  Aarayalum ninte uppa aakathirinnal matahi.kash...          NOT   \n",
       "600  Enna URL Njan nale neram veluthitt varam, ille...          NOT   \n",
       "609  @USER Abisher da potta lolanea kanikkunnudallo...          NOT   \n",
       "658  Njan oru muslim aan,full support chechee,enik ...          NOT   \n",
       "717      Mole achanteyum ammayudem vila ariyathondaaaa          NOT   \n",
       "719  Ninaku.pattumengil.sthree.kalku.upakaramulla.k...          NOT   \n",
       "755  Ahana chachiii nalla video aaaa egane parayunn...          NOT   \n",
       "780  first night video ittamathiyayirunnu veetukark...          OFF   \n",
       "\n",
       "    predicted_label        NOT       OFF  status  \n",
       "3               NOT   0.620587  0.379413   False  \n",
       "11              NOT   0.793384  0.206616   False  \n",
       "19              NOT   0.554235  0.445765   False  \n",
       "49              NOT   0.621288  0.378712   False  \n",
       "67              OFF   0.332914  0.667086   False  \n",
       "74              NOT   0.626035  0.373965   False  \n",
       "78              OFF   0.436869  0.563131   False  \n",
       "99              OFF   0.362424  0.637576   False  \n",
       "112             OFF   0.190991  0.809009   False  \n",
       "128             NOT   0.534747  0.465253   False  \n",
       "161             NOT   0.809044  0.190956   False  \n",
       "167             OFF  0.0262124  0.973788   False  \n",
       "176             OFF   0.275575  0.724425   False  \n",
       "182             OFF   0.265187  0.734813   False  \n",
       "211             OFF   0.288692  0.711308   False  \n",
       "229             NOT   0.700627  0.299373   False  \n",
       "254             OFF   0.282211  0.717789   False  \n",
       "256             OFF   0.386068  0.613932   False  \n",
       "261             OFF   0.440264  0.559736   False  \n",
       "262             OFF   0.454729  0.545271   False  \n",
       "281             OFF   0.340738  0.659262   False  \n",
       "295             OFF   0.358545  0.641455   False  \n",
       "301             OFF   0.275961  0.724039   False  \n",
       "334             OFF   0.311947  0.688053   False  \n",
       "345             OFF   0.250766  0.749234   False  \n",
       "348             NOT   0.568671  0.431329   False  \n",
       "350             NOT   0.787705  0.212295   False  \n",
       "373             OFF   0.375419  0.624581   False  \n",
       "407             OFF   0.458721  0.541279   False  \n",
       "473             NOT   0.514512  0.485488   False  \n",
       "490             OFF   0.494072  0.505928   False  \n",
       "531             OFF   0.481966  0.518034   False  \n",
       "544             OFF   0.325437  0.674563   False  \n",
       "579             OFF   0.493561  0.506439   False  \n",
       "585             OFF   0.472334  0.527666   False  \n",
       "600             OFF    0.16658   0.83342   False  \n",
       "609             OFF   0.276147  0.723853   False  \n",
       "658             OFF   0.498726  0.501274   False  \n",
       "717             OFF   0.228978  0.771022   False  \n",
       "719             OFF   0.278984  0.721016   False  \n",
       "755             OFF   0.462916  0.537084   False  \n",
       "780             NOT   0.691978  0.308022   False  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['status'] = df_result['actual_label']==df_result['predicted_label'] \n",
    "df_result[df_result['status']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('val_res_enml.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>NOT</th>\n",
       "      <th>OFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MA_YT5000</td>\n",
       "      <td>Chenkol vendath thanne aayirunnu....</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.974851</td>\n",
       "      <td>0.0251488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA_YT5001</td>\n",
       "      <td>Sundardasinte bhakshnam vakkukal ano?</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.0635997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MA_YT5002</td>\n",
       "      <td>Akasha dooth oru copy adi movie anu 'Who will ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.441635</td>\n",
       "      <td>0.558365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MA_YT5003</td>\n",
       "      <td>Purath onnum pondade... oru pennum payyanum on...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.75176</td>\n",
       "      <td>0.24824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MA_YT5004</td>\n",
       "      <td>Avasanam Fahad oru Oscar medikkumbazhum lalett...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.934347</td>\n",
       "      <td>0.0656529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text label  \\\n",
       "0  MA_YT5000               Chenkol vendath thanne aayirunnu....   NOT   \n",
       "1  MA_YT5001              Sundardasinte bhakshnam vakkukal ano?   NOT   \n",
       "2  MA_YT5002  Akasha dooth oru copy adi movie anu 'Who will ...   OFF   \n",
       "3  MA_YT5003  Purath onnum pondade... oru pennum payyanum on...   NOT   \n",
       "4  MA_YT5004  Avasanam Fahad oru Oscar medikkumbazhum lalett...   NOT   \n",
       "\n",
       "        NOT        OFF  \n",
       "0  0.974851  0.0251488  \n",
       "1    0.9364  0.0635997  \n",
       "2  0.441635   0.558365  \n",
       "3   0.75176    0.24824  \n",
       "4  0.934347  0.0656529  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(path/'../hasoc_task_2/malayalam_hasoc_tanglish_test_without_labels.tsv', sep='\\t', header=None)\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'id': list(df_test[0]), 'text': list(df_test[1]), 'label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train['Labels']))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "for index, row in df_result.iterrows():\n",
    "    pred = learn.predict(row['text'])\n",
    "    for node in all_nodes:\n",
    "        row[node] = pred[2][learn.data.c2i[node]].item()\n",
    "    row['label'] = i2c[pred[1].data.item()]\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(505, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result['label']=='NOT'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(951, 5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('test_res_enml_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
